"""
ë™ì  Extend ì›Œí¬í”Œë¡œìš° ë¹Œë”
ë¹„ë””ì˜¤ ê¸¸ì´ì— ë”°ë¼ í•„ìš”í•œ ë§Œí¼ Extend ë¸”ë¡ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
"""
import json
import cv2
import logging

logger = logging.getLogger(__name__)

# Extend ë¸”ë¡ì˜ ë…¸ë“œ ID íŒ¨í„´
# ê° Extend ë¸”ë¡ì€ ê³ ìœ í•œ base_idë¥¼ ê°€ì§‘ë‹ˆë‹¤
# ì²« ë²ˆì§¸: 263, ë‘ ë²ˆì§¸: 297, ì„¸ ë²ˆì§¸: 311, ...
# íŒ¨í„´: base_id = 263 + (extend_index * 34)

EXTEND_BASE_IDS = [263, 297, 311]  # ê¸°ì¡´ 3extendì—ì„œ ì‚¬ìš©ëœ IDë“¤
# ë” ë§ì€ extendê°€ í•„ìš”í•˜ë©´: [263, 297, 311, 345, 379, ...] (34ì”© ì¦ê°€)

# ê° Extend ë¸”ë¡ì˜ ë…¸ë“œ íƒ€ì…
EXTEND_NODE_TYPES = {
    "260": "GetImageSizeAndCount",
    "243": "ImageBatchExtendWithOverlap",
    "258": "WanVideoEncode",
    "261": "WanVideoAddOneToAllExtendEmbeds",
    "251": "WanVideoAddOneToAllPoseEmbeds",
    "248": "WanVideoSampler",
    "247": "WanVideoDecode",
    "249": "ImageBatchExtendWithOverlap"
}


def get_video_frame_count(video_path):
    """ë¹„ë””ì˜¤ì˜ ì´ í”„ë ˆì„ ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        cap.release()
        return frame_count
    except Exception as e:
        logger.error(f"ë¹„ë””ì˜¤ í”„ë ˆì„ ìˆ˜ ì¸¡ì • ì‹¤íŒ¨: {e}")
        raise


def calculate_extend_count(total_frames, window_size=81, overlap=5):
    """
    í•„ìš”í•œ Extend íšŸìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        total_frames: ë¹„ë””ì˜¤ì˜ ì´ í”„ë ˆì„ ìˆ˜
        window_size: í•œ ë²ˆì— ì²˜ë¦¬í•  í”„ë ˆì„ ìˆ˜ (ê¸°ë³¸ê°’: 81)
        overlap: ê° Extend ë¸”ë¡ ê°„ ì˜¤ë²„ë© í”„ë ˆì„ ìˆ˜ (ê¸°ë³¸ê°’: 5)
    
    Returns:
        í•„ìš”í•œ Extend íšŸìˆ˜
    """
    if total_frames <= window_size:
        return 0
    
    # ì²« ë²ˆì§¸ window_size í”„ë ˆì„ì€ ê¸°ë³¸ ì›Œí¬í”Œë¡œìš°ì—ì„œ ì²˜ë¦¬
    remaining_frames = total_frames - window_size
    
    # ê° ExtendëŠ” (window_size - overlap)ë§Œí¼ì˜ ìƒˆë¡œìš´ í”„ë ˆì„ì„ ìƒì„±
    frames_per_extend = window_size - overlap
    
    # í•„ìš”í•œ Extend íšŸìˆ˜ ê³„ì‚°
    extend_count = (remaining_frames + frames_per_extend - 1) // frames_per_extend
    
    return max(0, extend_count)


def get_extend_base_id(extend_index):
    """
    Extend ë¸”ë¡ì˜ base IDë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        extend_index: Extend ë¸”ë¡ì˜ ì¸ë±ìŠ¤ (0ë¶€í„° ì‹œì‘)
    
    Returns:
        base ID (ì˜ˆ: 263, 297, 311, ...)
    """
    if extend_index < len(EXTEND_BASE_IDS):
        return EXTEND_BASE_IDS[extend_index]
    else:
        # íŒ¨í„´: 263 + (extend_index * 34)
        return 263 + (extend_index * 34)


def create_extend_block(base_id, prev_output_node, overlap_node, scheduler_node, 
                       cfg_node, vae_node, model_node, text_embeds_node, 
                       pose_images_node, pose_prefix_node, ref_embeds_node):
    """
    í•˜ë‚˜ì˜ Extend ë¸”ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        base_id: ì´ Extend ë¸”ë¡ì˜ base ID
        prev_output_node: ì´ì „ ë¸”ë¡ì˜ ì¶œë ¥ ë…¸ë“œ ID
        overlap_node: overlap ê°’ì„ ê°€ì§„ ë…¸ë“œ ID (ì˜ˆ: "169")
        scheduler_node: scheduler ë…¸ë“œ ID (ì˜ˆ: "231")
        cfg_node: CFG ë…¸ë“œ ID (ì˜ˆ: "238")
        vae_node: VAE ë…¸ë“œ ID (ì˜ˆ: "38")
        model_node: ëª¨ë¸ ë…¸ë“œ ID (ì˜ˆ: "80")
        text_embeds_node: í…ìŠ¤íŠ¸ embeds ë…¸ë“œ ID (ì˜ˆ: "16")
        pose_images_node: í¬ì¦ˆ ì´ë¯¸ì§€ ë…¸ë“œ ID (ì˜ˆ: "141")
        pose_prefix_node: í¬ì¦ˆ prefix ì´ë¯¸ì§€ ë…¸ë“œ ID (ì˜ˆ: "141", output 1)
        ref_embeds_node: ì°¸ì¡° embeds ë…¸ë“œ ID (ì˜ˆ: "105")
    
    Returns:
        Extend ë¸”ë¡ì˜ ë…¸ë“œ ë”•ì…”ë„ˆë¦¬
    """
    nodes = {}
    
    # 1. GetImageSizeAndCount (260)
    nodes[f"{base_id}:260"] = {
        "inputs": {
            "image": [prev_output_node, 0]
        },
        "class_type": "GetImageSizeAndCount",
        "_meta": {
            "title": "Get Image Size & Count"
        }
    }
    
    # 2. ImageBatchExtendWithOverlap (243) - ì²« ë²ˆì§¸
    nodes[f"{base_id}:243"] = {
        "inputs": {
            "overlap": [overlap_node, 0],
            "overlap_side": "source",
            "overlap_mode": "linear_blend",
            "source_images": [f"{base_id}:260", 0]
        },
        "class_type": "ImageBatchExtendWithOverlap",
        "_meta": {
            "title": "Image Batch Extend With Overlap"
        }
    }
    
    # 3. WanVideoEncode (258)
    nodes[f"{base_id}:258"] = {
        "inputs": {
            "enable_vae_tiling": False,
            "tile_x": 272,
            "tile_y": 272,
            "tile_stride_x": 144,
            "tile_stride_y": 128,
            "noise_aug_strength": 0,
            "latent_strength": 1,
            "vae": [vae_node, 0],
            "image": [f"{base_id}:243", 1]
        },
        "class_type": "WanVideoEncode",
        "_meta": {
            "title": "WanVideo Encode"
        }
    }
    
    # 4. WanVideoAddOneToAllExtendEmbeds (261)
    nodes[f"{base_id}:261"] = {
        "inputs": {
            "window_size": 81,
            "overlap": [overlap_node, 0],
            "frames_processed": [f"{base_id}:260", 3],
            "if_not_enough_frames": "pad_with_last",
            "embeds": [ref_embeds_node, 0],
            "prev_latents": [f"{base_id}:258", 0],
            "pose_images": [pose_images_node, 0]
        },
        "class_type": "WanVideoAddOneToAllExtendEmbeds",
        "_meta": {
            "title": "WanVideo Add OneToAll Extend Embeds"
        }
    }
    
    # 5. WanVideoAddOneToAllPoseEmbeds (251)
    nodes[f"{base_id}:251"] = {
        "inputs": {
            "strength": 1,
            "start_percent": 0,
            "end_percent": 1,
            "embeds": [f"{base_id}:261", 0],
            "pose_images": [f"{base_id}:261", 1],
            "pose_prefix_image": [pose_prefix_node, 1]
        },
        "class_type": "WanVideoAddOneToAllPoseEmbeds",
        "_meta": {
            "title": "WanVideo Add OneToAll Pose Embeds"
        }
    }
    
    # 6. WanVideoSampler (248)
    nodes[f"{base_id}:248"] = {
        "inputs": {
            "steps": 6,
            "cfg": [cfg_node, 0],
            "shift": 7,
            "seed": 0,
            "force_offload": True,
            "scheduler": [scheduler_node, 3],
            "riflex_freq_index": 0,
            "denoise_strength": 1,
            "batched_cfg": False,
            "rope_function": "comfy",
            "start_step": 0,
            "end_step": -1,
            "add_noise_to_samples": "",
            "model": [model_node, 0],
            "image_embeds": [f"{base_id}:251", 0],
            "text_embeds": [text_embeds_node, 0]
        },
        "class_type": "WanVideoSampler",
        "_meta": {
            "title": "WanVideo Sampler"
        }
    }
    
    # 7. WanVideoDecode (247)
    nodes[f"{base_id}:247"] = {
        "inputs": {
            "enable_vae_tiling": False,
            "tile_x": 272,
            "tile_y": 272,
            "tile_stride_x": 144,
            "tile_stride_y": 128,
            "normalization": "default",
            "vae": [vae_node, 0],
            "samples": [f"{base_id}:248", 0]
        },
        "class_type": "WanVideoDecode",
        "_meta": {
            "title": "WanVideo Decode"
        }
    }
    
    # 8. ImageBatchExtendWithOverlap (249) - ìµœì¢… ë³‘í•©
    nodes[f"{base_id}:249"] = {
        "inputs": {
            "overlap": [overlap_node, 0],
            "overlap_side": "source",
            "overlap_mode": "linear_blend",
            "source_images": [f"{base_id}:243", 0],
            "new_images": [f"{base_id}:247", 0]
        },
        "class_type": "ImageBatchExtendWithOverlap",
        "_meta": {
            "title": "Image Batch Extend With Overlap"
        }
    }
    
    return nodes


def build_dynamic_workflow(base_workflow_path, video_path, output_node_id="139"):
    """
    ë¹„ë””ì˜¤ ê¸¸ì´ì— ë”°ë¼ ë™ì ìœ¼ë¡œ Extend ë¸”ë¡ì„ ì¶”ê°€í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        base_workflow_path: ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° íŒŒì¼ ê²½ë¡œ
        video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        output_node_id: ìµœì¢… ì¶œë ¥ ë…¸ë“œ ID (ê¸°ë³¸ê°’: "139")
    
    Returns:
        ë™ì ìœ¼ë¡œ ìƒì„±ëœ ì›Œí¬í”Œë¡œìš° ë”•ì…”ë„ˆë¦¬
    """
    # ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° ë¡œë“œ
    with open(base_workflow_path, 'r', encoding='utf-8') as f:
        workflow = json.load(f)
    
    # ë¹„ë””ì˜¤ ë¡œë“œ ë…¸ë“œ ì„¤ì • ìˆ˜ì •
    if "130" in workflow:
        # frame_load_cap ì œê±° (ë¬´ì œí•œìœ¼ë¡œ ì„¤ì •)
        if "frame_load_cap" in workflow["130"]["inputs"]:
            workflow["130"]["inputs"]["frame_load_cap"] = 0
        # force_rateë¥¼ 16ìœ¼ë¡œ ì„¤ì •
        workflow["130"]["inputs"]["force_rate"] = 16
    
    # ë¹„ë””ì˜¤ í”„ë ˆì„ ìˆ˜ ê³„ì‚°
    total_frames = get_video_frame_count(video_path)
    logger.info(f"ë¹„ë””ì˜¤ ì´ í”„ë ˆì„ ìˆ˜: {total_frames}")
    
    # í•„ìš”í•œ Extend íšŸìˆ˜ ê³„ì‚°
    extend_count = calculate_extend_count(total_frames)
    logger.info(f"í•„ìš”í•œ Extend íšŸìˆ˜: {extend_count}")
    
    # ê¸°ë³¸ ì¶œë ¥ ë…¸ë“œ ì„¤ì •
    if extend_count == 0:
        # Extendê°€ í•„ìš” ì—†ìœ¼ë©´ ê¸°ë³¸ ì›Œí¬í”Œë¡œìš°ì˜ ì¶œë ¥ ë…¸ë“œ ì‚¬ìš©
        prev_output_node = "28"
    else:
        prev_output_node = None  # ë‚˜ì¤‘ì— ì„¤ì •ë¨
    
    # Extend ë¸”ë¡ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ìƒì„±
    if extend_count > 0:
        # ê¸°ë³¸ ì›Œí¬í”Œë¡œìš°ì˜ ì£¼ìš” ë…¸ë“œ ID ì¶”ì¶œ
        # (onetoall_0extend.json ê¸°ì¤€)
        base_output_node = "28"  # ê¸°ë³¸ ì›Œí¬í”Œë¡œìš°ì˜ ì¶œë ¥ ë…¸ë“œ
        overlap_node = "169"
        scheduler_node = "231"
        cfg_node = "238"
        vae_node = "38"
        model_node = "80"
        text_embeds_node = "16"
        pose_images_node = "141"
        pose_prefix_node = "141"  # output 1
        ref_embeds_node = "105"
        
        # ê° Extend ë¸”ë¡ ìƒì„± ë° ì—°ê²°
        prev_output_node = base_output_node
        
        for i in range(extend_count):
            base_id = get_extend_base_id(i)
            logger.info(f"Extend ë¸”ë¡ {i+1}/{extend_count} ìƒì„± ì¤‘ (base_id: {base_id})...")
            
            # Extend ë¸”ë¡ ìƒì„±
            extend_nodes = create_extend_block(
                base_id=base_id,
                prev_output_node=prev_output_node,
                overlap_node=overlap_node,
                scheduler_node=scheduler_node,
                cfg_node=cfg_node,
                vae_node=vae_node,
                model_node=model_node,
                text_embeds_node=text_embeds_node,
                pose_images_node=pose_images_node,
                pose_prefix_node=pose_prefix_node,
                ref_embeds_node=ref_embeds_node
            )
        
            # ì›Œí¬í”Œë¡œìš°ì— ë…¸ë“œ ì¶”ê°€
            workflow.update(extend_nodes)
            
            # ë‹¤ìŒ Extend ë¸”ë¡ì„ ìœ„í•œ ì´ì „ ì¶œë ¥ ë…¸ë“œ ì—…ë°ì´íŠ¸
            prev_output_node = f"{base_id}:249"
    
    # RIFE í”„ë ˆì„ ë³´ê°„ ë…¸ë“œ ì¶”ê°€ (video combine ì§ì „)
    # RIFE ë…¸ë“œ ID ìƒì„± (ê¸°ì¡´ ë…¸ë“œ IDì™€ ì¶©ëŒí•˜ì§€ ì•Šë„ë¡ í° ë²ˆí˜¸ ì‚¬ìš©)
    rife_node_id = "500"
    
    # RIFE ë…¸ë“œ ìƒì„± (16fps -> 32fpsë¡œ ë³´ê°„, multiplier=2)
    workflow[rife_node_id] = {
        "inputs": {
            "ckpt_name": "rife49.pth",
            "clear_cache_after_n_frames": 10,
            "multiplier": 2,
            "fast_mode": True,
            "ensemble": True,
            "scale_factor": 4,
            "frames": [prev_output_node, 0]
        },
        "class_type": "RIFE VFI",
        "_meta": {
            "title": "RIFE VFI (recommend rife47 and rife49)"
        }
    }
    logger.info(f"RIFE í”„ë ˆì„ ë³´ê°„ ë…¸ë“œ '{rife_node_id}' ìƒì„± (16fps -> 32fps)")
    
    # ìµœì¢… ì¶œë ¥ ë…¸ë“œ ì—…ë°ì´íŠ¸
    # output_node_idê°€ "139"ì¸ ê²½ìš° (VHS_VideoCombine)
    if output_node_id in workflow:
        # RIFE ë…¸ë“œì˜ ì¶œë ¥ì„ video combineì— ì—°ê²°
        workflow[output_node_id]["inputs"]["images"] = [rife_node_id, 0]
        # frame_rateë¥¼ 32ë¡œ ì„¤ì • (RIFEë¡œ 2ë°° ë³´ê°„í–ˆìœ¼ë¯€ë¡œ)
        workflow[output_node_id]["inputs"]["frame_rate"] = 32
        logger.info(f"ìµœì¢… ì¶œë ¥ ë…¸ë“œ '{output_node_id}'ë¥¼ RIFE ë…¸ë“œ '{rife_node_id}'ì— ì—°ê²°í–ˆìŠµë‹ˆë‹¤ (32fps).")
    else:
        # ì¶œë ¥ ë…¸ë“œê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        workflow[output_node_id] = {
            "inputs": {
                "frame_rate": 32,
                "loop_count": 0,
                "filename_prefix": "WanVideo_OneToAllAnimation",
                "format": "video/h264-mp4",
                "pix_fmt": "yuv420p",
                "crf": 19,
                "save_metadata": True,
                "trim_to_audio": False,
                "pingpong": False,
                "save_output": False,
                "images": [rife_node_id, 0]
            },
            "class_type": "VHS_VideoCombine",
            "_meta": {
                "title": "Video Combine ğŸ¥ğŸ…¥ğŸ…—ğŸ…¢"
            }
        }
        logger.info(f"ìƒˆë¡œìš´ ì¶œë ¥ ë…¸ë“œ '{output_node_id}'ë¥¼ ìƒì„±í•˜ê³  RIFE ë…¸ë“œ '{rife_node_id}'ì— ì—°ê²°í–ˆìŠµë‹ˆë‹¤ (32fps).")
    
    return workflow


def save_workflow(workflow, output_path):
    """ì›Œí¬í”Œë¡œìš°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(workflow, f, indent=2, ensure_ascii=False)
    logger.info(f"ì›Œí¬í”Œë¡œìš°ë¥¼ '{output_path}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 3:
        print("ì‚¬ìš©ë²•: python workflow_builder.py <base_workflow.json> <video_path> [output_workflow.json]")
        sys.exit(1)
    
    base_workflow_path = sys.argv[1]
    video_path = sys.argv[2]
    output_path = sys.argv[3] if len(sys.argv) > 3 else "dynamic_workflow.json"
    
    workflow = build_dynamic_workflow(base_workflow_path, video_path)
    save_workflow(workflow, output_path)
    print(f"âœ… ë™ì  ì›Œí¬í”Œë¡œìš° ìƒì„± ì™„ë£Œ: {output_path}")

